---
title: "Webscraping"

execute: 
  eval: false
---

```{r}
library(tidyverse)
library(scales)
library(quanteda)
library(quanteda.textstats)
library(httr)
library(rvest)
library(polite)

### Fichier TP_pets_website.csv

##### Scraping sites web
url_start<-"https://fr.trustpilot.com/categories/animals_pets"

trustpilot_website<-function(url_start){

session <- bow(url_start)
session$user_agent<-"Googlebot"
message("Scraping ", url_start)
page<-nod(session, url_start) %>% 
  scrape(verbose=TRUE)
i<-page%>%html_elements(".styles_paginationWrapper__fukEb")%>%
  html_element("a.button_button__T34Lr:nth-child(5)")%>%
  html_text()%>%as.numeric()
website <- NULL

for (j in 1:i){
  url<-paste0(url_start,"?page=",j)
  Sys.sleep(5)
  session <- bow(url)
  session$user_agent<-"Googlebot"
  message("Scraping ", url)
  page<-nod(session, url) %>% 
      scrape(verbose=TRUE)
    
    company_card <- page %>%
      html_elements("div.styles_wrapper__2JOo2:nth-of-type(n+4)")
    
    website_name <- company_card %>%
      html_element("p.typography_heading-xs__jSwUz") %>%
      html_text()
    
    nb_avis <- company_card %>%
      html_element("p.typography_body-m__xgxZ_")%>%
      html_text()
    
    localisation <- company_card%>%
      html_element("span.styles_metadataItem__Qn_Q2")%>%
      html_text()

    type <- company_card %>%
      html_element("div.styles_desktop__U5iWw") %>%
      html_text()
    
    lien <- paste0("https://fr.trustpilot.com", company_card %>%
               html_element("a")%>%html_attr("href"))
      
    
    website <- rbind(website, data.frame(
      website_name = website_name, 
      nb_avis = nb_avis,
      localisation = localisation,
      type = type,
      lien = lien
    ))
  print(paste("page",j, "has been scraped"))
    
j<-j+1

}
return(website)

}

website<-trustpilot_website(url_start = url_start)

##### Création du fichier TP_pets_website.csv
website<-website%>%mutate(note=str_split_i(nb_avis,"\\|", 1)%>%
                      str_remove_all(., "[A-z]")%>%
                      str_replace(., ",", ".")%>%
                      as.numeric(),
                    nb_avis=str_split_i(nb_avis,"\\|",2)%>%
                      str_remove_all(., "[A-z]")%>%
                      str_remove_all(., "[:space:]")%>%
                      as.numeric()%>%
                      replace_na(.,0),
                    url_start=url_start,
                    nb_page=0,
                    cat=str_split(type, "·"))%>%
  unnest_wider(cat, names_sep = "_")

data_scrap<-website%>%filter(nb_avis>10)
write_csv(data_scrap, "TP_pets_website.csv")


### Fichier TP_pets_reviews.rds

##### Scraping reviews

trustpilot_reviews<-function(data){
  Sys.sleep(5)
  
  for (j in 1:nrow(data)) {
    i<-1
    b<-1
    
    
    while (b!="TRUE") {
      
      Sys.sleep(5)
      
      
      b<-http_error(paste0(data$lien[j], "?languages=all&page=", i))
      
      i<-i+1
      data$nb_page[j]<-i-2
      
    }
    print(paste0("nb_page of ", data$website_name[j], " has been fetched"))
    
  }
  
  i<-1
  reviews <- NULL
  # cat("\014")
  cat(paste0("The script will run on ", sum(data$nb_page), " pages!\n"))
  Sys.sleep(5)
  
  
  for (j in 1: nrow(data)){
    for (i in 1:data$nb_page[j]){
      url<-paste0(data$lien[j],"?languages=all&page=",i)
      Sys.sleep(5)
      session <- bow(url)
      session$user_agent<-"Googlebot"
      message("Scraping ", url)
      page<-nod(session, url) %>% 
        scrape(verbose=TRUE)
      
      review_card <- page %>%
        html_elements("div.styles_reviewCardInner__EwDq2")
      
      name <- review_card %>%
        html_element("span.typography_heading-xxs__QKBS8.typography_appearance-default__AAY17") %>%
        html_text()
      
      rating <- review_card %>%
        html_elements("div.star-rating_starRating__4rrcf.star-rating_medium__iN6Ty") %>%
        html_element("img")%>%
        html_attr("alt")%>%
        str_extract("[:digit:]")
      
      published <- review_card%>%
        html_elements(".styles_reviewContentwrapper__zH_9M")%>%
        html_element("p.typography_body-m__xgxZ_")%>%
        html_text()%>%
        str_remove("Date de l'expérience: ")
      
      verified <- review_card %>%
        html_element(".styles_detailsIcon__yqwWi") %>%
        html_text()
      
      title <- review_card %>%
        html_element("h2")%>%
        html_text()
      
      content <- review_card%>%
        html_elements(".styles_reviewContentwrapper__zH_9M")%>%
        html_element("p.typography_body-l__KUYFJ") %>%
        html_text2()
      
      
      reviews <- rbind(reviews, data.frame(
        website_name = data$website_name[j],
        name = name, 
        rating = rating,
        published = published,
        verified = verified,
        title = title, 
        content = content
      ))
      
      i<-i+1
    }
    print(paste0(data$website_name[j], " has been scraped"))
    
    j<-j+1
  }

  return(reviews)
}

hak<-trustpilot_reviews(data_scrap)

```

