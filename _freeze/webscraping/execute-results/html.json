{
  "hash": "beaf274df7bbf690a78713b8b6ea58de",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Webscraping\"\n\nexecute: \n  eval: false\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(quanteda)\nlibrary(quanteda.textstats)\nlibrary(httr)\nlibrary(rvest)\nlibrary(polite)\n\n### Fichier TP_pets_website.csv\n\n##### Scraping sites web\nurl_start<-\"https://fr.trustpilot.com/categories/animals_pets\"\n\ntrustpilot_website<-function(url_start){\n\nsession <- bow(url_start)\nsession$user_agent<-\"Googlebot\"\nmessage(\"Scraping \", url_start)\npage<-nod(session, url_start) %>% \n  scrape(verbose=TRUE)\ni<-page%>%html_elements(\".styles_paginationWrapper__fukEb\")%>%\n  html_element(\"a.button_button__T34Lr:nth-child(5)\")%>%\n  html_text()%>%as.numeric()\nwebsite <- NULL\n\nfor (j in 1:i){\n  url<-paste0(url_start,\"?page=\",j)\n  Sys.sleep(5)\n  session <- bow(url)\n  session$user_agent<-\"Googlebot\"\n  message(\"Scraping \", url)\n  page<-nod(session, url) %>% \n      scrape(verbose=TRUE)\n    \n    company_card <- page %>%\n      html_elements(\"div.styles_wrapper__2JOo2:nth-of-type(n+4)\")\n    \n    website_name <- company_card %>%\n      html_element(\"p.typography_heading-xs__jSwUz\") %>%\n      html_text()\n    \n    nb_avis <- company_card %>%\n      html_element(\"p.typography_body-m__xgxZ_\")%>%\n      html_text()\n    \n    localisation <- company_card%>%\n      html_element(\"span.styles_metadataItem__Qn_Q2\")%>%\n      html_text()\n\n    type <- company_card %>%\n      html_element(\"div.styles_desktop__U5iWw\") %>%\n      html_text()\n    \n    lien <- paste0(\"https://fr.trustpilot.com\", company_card %>%\n               html_element(\"a\")%>%html_attr(\"href\"))\n      \n    \n    website <- rbind(website, data.frame(\n      website_name = website_name, \n      nb_avis = nb_avis,\n      localisation = localisation,\n      type = type,\n      lien = lien\n    ))\n  print(paste(\"page\",j, \"has been scraped\"))\n    \nj<-j+1\n\n}\nreturn(website)\n\n}\n\nwebsite<-trustpilot_website(url_start = url_start)\n\n##### Création du fichier TP_pets_website.csv\nwebsite<-website%>%mutate(note=str_split_i(nb_avis,\"\\\\|\", 1)%>%\n                      str_remove_all(., \"[A-z]\")%>%\n                      str_replace(., \",\", \".\")%>%\n                      as.numeric(),\n                    nb_avis=str_split_i(nb_avis,\"\\\\|\",2)%>%\n                      str_remove_all(., \"[A-z]\")%>%\n                      str_remove_all(., \"[:space:]\")%>%\n                      as.numeric()%>%\n                      replace_na(.,0),\n                    url_start=url_start,\n                    nb_page=0,\n                    cat=str_split(type, \"·\"))%>%\n  unnest_wider(cat, names_sep = \"_\")\n\ndata_scrap<-website%>%filter(nb_avis>10)\nwrite_csv(data_scrap, \"TP_pets_website.csv\")\n\n\n### Fichier TP_pets_reviews.rds\n\n##### Scraping reviews\n\ntrustpilot_reviews<-function(data){\n  Sys.sleep(5)\n  \n  for (j in 1:nrow(data)) {\n    i<-1\n    b<-1\n    \n    \n    while (b!=\"TRUE\") {\n      \n      Sys.sleep(5)\n      \n      \n      b<-http_error(paste0(data$lien[j], \"?languages=all&page=\", i))\n      \n      i<-i+1\n      data$nb_page[j]<-i-2\n      \n    }\n    print(paste0(\"nb_page of \", data$website_name[j], \" has been fetched\"))\n    \n  }\n  \n  i<-1\n  reviews <- NULL\n  # cat(\"\\014\")\n  cat(paste0(\"The script will run on \", sum(data$nb_page), \" pages!\\n\"))\n  Sys.sleep(5)\n  \n  \n  for (j in 1: nrow(data)){\n    for (i in 1:data$nb_page[j]){\n      url<-paste0(data$lien[j],\"?languages=all&page=\",i)\n      Sys.sleep(5)\n      session <- bow(url)\n      session$user_agent<-\"Googlebot\"\n      message(\"Scraping \", url)\n      page<-nod(session, url) %>% \n        scrape(verbose=TRUE)\n      \n      review_card <- page %>%\n        html_elements(\"div.styles_reviewCardInner__EwDq2\")\n      \n      name <- review_card %>%\n        html_element(\"span.typography_heading-xxs__QKBS8.typography_appearance-default__AAY17\") %>%\n        html_text()\n      \n      rating <- review_card %>%\n        html_elements(\"div.star-rating_starRating__4rrcf.star-rating_medium__iN6Ty\") %>%\n        html_element(\"img\")%>%\n        html_attr(\"alt\")%>%\n        str_extract(\"[:digit:]\")\n      \n      published <- review_card%>%\n        html_elements(\".styles_reviewContentwrapper__zH_9M\")%>%\n        html_element(\"p.typography_body-m__xgxZ_\")%>%\n        html_text()%>%\n        str_remove(\"Date de l'expérience: \")\n      \n      verified <- review_card %>%\n        html_element(\".styles_detailsIcon__yqwWi\") %>%\n        html_text()\n      \n      title <- review_card %>%\n        html_element(\"h2\")%>%\n        html_text()\n      \n      content <- review_card%>%\n        html_elements(\".styles_reviewContentwrapper__zH_9M\")%>%\n        html_element(\"p.typography_body-l__KUYFJ\") %>%\n        html_text2()\n      \n      \n      reviews <- rbind(reviews, data.frame(\n        website_name = data$website_name[j],\n        name = name, \n        rating = rating,\n        published = published,\n        verified = verified,\n        title = title, \n        content = content\n      ))\n      \n      i<-i+1\n    }\n    print(paste0(data$website_name[j], \" has been scraped\"))\n    \n    j<-j+1\n  }\n\n  return(reviews)\n}\n\nhak<-trustpilot_reviews(data_scrap)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}