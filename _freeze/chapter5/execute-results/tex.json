{
  "hash": "65f5266481675ab495a7ebcfd1d4bff6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"*Topic Analysis*\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(quanteda)\nlibrary(quanteda.textstats)\nlibrary(quanteda.textplots)\nlibrary(RColorBrewer)\nlibrary(topicmodels)\nlibrary(ggwordcloud)\n```\n:::\n\n\n\n# Les données\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read_csv(\"data/data_trustpilot_oiseaux.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 4388 Columns: 7\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (4): auteur, date, month, comments\ndbl (3): id, year, note\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n# *Topics Analysis*\n\nOn va maintenant s'intéresser à la détection et à l'analyse de topics. Il existe de nombreux algorithmes pour cela. On va en explorer un : le modèle LDA, pour Latent Dirichlet Allocation.\n\n-   Description du modèle LDA :\n\nL'idée est la suivante : un corpus est considéré comme une collection de documents. Chaque document est considéré comme étant composé d'un mélange de topics. Chaque topic est considéré comme étant composé d'un mélange de tokens. L'algorithme calcule par itération les probabilités d'appartenance des tokens aux topics et des topics aux documents, ce qui nous permet de visualiser la composition des sujets identifiés.\n\n![Le modèle LDA](lda.png)\n\n## Le modèle LDA avec topicmodels\n\nOn travaille à partir du dfm. On doit transformer le format des données afin de l'injecter dans le modèle. On réduit le nombre de termes considérés, ce qui permet de réduire les temps de calcul et de trouver une solution convergente.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorpus_oiseaux<-corpus(data, text_field = \"comments\")\n\ntok<-tokens(corpus_oiseaux, remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE)%>%\n  tokens_remove(stopwords(\"fr\"))\n\ndfm<-dfm(tok)\n\n\n#On filtre les mots trop et trop peu fréquents\nrem<-c(\"très\",\"rapide\",\"produit\",\"livraison\", \"commande\", \"bien\", \"site\", \"a\", \"bon\", \"merci\", \"recommande\",\"parfait\")\n\nnews_dfm <- dfm %>%\n  dfm_remove(rem)%>%\n  dfm_trim(min_termfreq = 0.8, termfreq_type = \"quantile\",    # 80% des mots les plus fréquents\n           max_docfreq = 0.2, docfreq_type = \"prop\")          #qui apparaissent dans max 20% des documents\n\n#On supprime les entrées vides\nnews_dfm <- news_dfm[ntoken(news_dfm) > 0,]\n\n#On transforme en dtm, un format compris par le package topicsmodel\ndtm <- convert(news_dfm, to = \"topicmodels\")\n\n#On lance le modèle\nlda <- LDA(dtm, k = 5)\n\n#On regarde les résultats\nterms(lda,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Topic 1      Topic 2      Topic 3    Topic 4      Topic 5   \n [1,] \"produits\"   \"j'ai\"       \"super\"    \"produits\"   \"j'ai\"    \n [2,] \"rien\"       \"emballé\"    \"qualité\"  \"qualité\"    \"rapidité\"\n [3,] \"rapidement\" \"reçu\"       \"mania\"    \"satisfaite\" \"oiseaux\" \n [4,] \"conforme\"   \"satisfaite\" \"prix\"     \"colis\"      \"reçu\"    \n [5,] \"service\"    \"toujours\"   \"bonne\"    \"reçu\"       \"c'est\"   \n [6,] \"prix\"       \"colis\"      \"problème\" \"toujours\"   \"colis\"   \n [7,] \"oiseaux\"    \"produits\"   \"tout\"     \"rapidement\" \"qualité\" \n [8,] \"choix\"      \"plus\"       \"oiseaux\"  \"envoi\"      \"tout\"    \n [9,] \"satisfait\"  \"envoi\"      \"tres\"     \"oiseaux\"    \"produits\"\n[10,] \"temps\"      \"prix\"       \"chez\"     \"j'ai\"       \"service\" \n```\n\n\n:::\n\n```{.r .cell-code}\n# topics(lda)\n\ncorpus_oiseaux[\"text996\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCorpus consisting of 1 document and 6 docvars.\ntext996 :\n\"Seconde commande, satisfaction totale, expédition très rapid...\"\n```\n\n\n:::\n\n```{.r .cell-code}\ncorpus_oiseaux[\"text995\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCorpus consisting of 1 document and 6 docvars.\ntext995 :\n\"Très bon produit. Livraison rapide et sérieux je recommande ...\"\n```\n\n\n:::\n\n```{.r .cell-code}\ncorpus_oiseaux[\"text999\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCorpus consisting of 1 document and 6 docvars.\ntext999 :\n\"Très bon magasin emballage dans les normes on y trouve de to...\"\n```\n\n\n:::\n:::\n\n\n\n## *Topic Analysis* à partir de l'annotation des *part of speech*\n\nLes résultats du modèle LDA sont très dépendants de la qualité du vocabulaire injecté. Plus on travaille ce vocabulaire, meilleurs sont les résultats. On va donc reprendre tout ce qu'on a fait jusqu'à présent pour améliorer les résultats de notre modèle : on récupère les annotations ; on filtre le vocabulaire pour ne garder que les noms, adjectifs et verbes ; on crée les collocations ; on filtre les occurrences trop et pas assez fréquentes.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nann_token<-read_rds(\"data/annotation_oiseaux.rds\")\n\n\ndata<-ann_token%>%\n  filter(upos==\"NOUN\"|upos==\"VERB\"|upos==\"ADJ\")%>%\n  group_by(doc_id)%>%\n  summarise(text=paste(lemma,collapse = \" \"))%>%\n  inner_join(data, join_by(\"doc_id\"==\"id\"))\n\ncorpus_new<-corpus(data, text_field = \"text\")\ntoks<-tokens(corpus_new)%>%\n  tokens_replace(c(\"produire\", \"conformer\",\"colir\"), c(\"produit\", \"conforme\",\"colis\"))%>%\n  tokens_remove(c(\".\",\",\"))\n\ncolloc<-textstat_collocations(toks, min_count = 10, tolower = TRUE)\n\ntoks<-tokens_compound(toks, pattern = colloc[colloc$z>7,])\n\n\ndfm_new<-dfm(toks)%>%\n  dfm_trim(min_termfreq = 0.6, termfreq_type = \"quantile\",\n           max_docfreq = 0.1, docfreq_type = \"prop\")\ndtm_new <- convert(dfm_new, to = \"topicmodels\")\n\nset.seed(1234)\nlda <- LDA(dtm_new, k = 5)\n\nterm<-as_tibble(terms(lda,25))%>%\n  mutate(rank=as.numeric(row.names(.)))%>%\n  pivot_longer(-rank, names_to = \"topic\",values_to = \"term\")\n\nggplot(term, aes(x=topic, y= rank, group =  term , label = term)) + \n  scale_y_reverse() +\n  geom_text(aes(color=topic,size=8/log(rank)))+\n  theme_minimal()+\n  scale_color_hue()+\n  guides(color=\"none\",size=\"none\")\n```\n\n::: {.cell-output-display}\n![](chapter5_files/figure-pdf/unnamed-chunk-1-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n## Déterminer le nombre de topics optimal\n\nLe modèle LDA fonctionne à partir d'un nombre de topics donné. La question est donc de savoir quel est le nombre de topics optimal pour décrire notre corpus. Heureusement, des personnes ont créé des fonctions et des procédures pour nous aider dans cette quête. L'idée est de calculer différents modèles pour différents nombres de topics, et de comparer la qualité des résultats. La procédure ci-dessous est en deux parties :\n\n-   Tout d'abord, on compare la qualité de différents indicateurs sur un grand nombre de modèles, pour aboutir à une liste de quelques solutions à comparer plus en détail (de 3 à 10).\n\n-   Ensuite, on compare les résultats de la liste réduite de modèles, pour déterminer lequel a la meilleure distribution des topics entre les documents. La distribution recherchée est celle qui distingue le plus les documents en fonction des topics, tout en étant à droite de l'estimation d'une répartition uniforme des documents entre les topics. Le critère de parcimonie nous invite à choisir la solution avec le moins grand nombre de topics, en cas de résultats comparables.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##Etape 1 : les meilleures solutions\nlibrary(ldatuning)\nlibrary(magrittr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttachement du package : 'magrittr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nL'objet suivant est masqué depuis 'package:purrr':\n\n    set_names\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nL'objet suivant est masqué depuis 'package:tidyr':\n\n    extract\n```\n\n\n:::\n\n```{.r .cell-code}\nresult <- FindTopicsNumber(dtm_new,\n                           topics = c(seq(from = 2, to = 9, by = 1), seq(10, 25, 5)),\n                           metrics = c(\"Griffiths2004\", \"CaoJuan2009\", \"Arun2010\", \"Deveaud2014\"),\n                           method = \"Gibbs\",\n                           control = list(seed = 0:4,\n                                          nstart = 5,\n                                          best = TRUE),\n                           mc.cores = 4L,\n                           verbose = TRUE\n                           )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfit models... done.\ncalculate metrics:\n  Griffiths2004... done.\n  CaoJuan2009... done.\n  Arun2010... done.\n  Deveaud2014... done.\n```\n\n\n:::\n\n```{.r .cell-code}\nFindTopicsNumber_plot(result)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\ni The deprecated feature was likely used in the ldatuning package.\n  Please report the issue at <https://github.com/nikita-moor/ldatuning/issues>.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](chapter5_files/figure-pdf/proc_topic-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\n##Etape 2 : comparaison des solutions\npara <- tibble(k = c(6,7,8,9,10))\nlemma_tm <- para %>%\n  mutate(lda = map(k,\n                   function(k) LDA(\n                     k=k,\n                     x=dtm_new,\n                     method=\"Gibbs\",\n                     control=list(seed = 0:4,\n                                  nstart = 5,\n                                  best = TRUE)\n                     )\n                   )\n         )\n\nlemma_tm <- lemma_tm %>%\n  mutate(lda_gamma = map(.x=lda,\n                         .f=tidytext::tidy,\n                         matrix=\"gamma\"))\nlemma_tm %>%\n  unnest(lda_gamma) %>%\n  group_by(k, document) %>%\n  arrange(desc(gamma)) %>%\n  slice(1) %>%\n  ungroup() %>%\n  ggplot(aes(x=gamma, fill=factor(k))) +\n  geom_histogram(bins = 20) +\n  scale_fill_discrete(name = \"Number of\\nTopics\") +\n  xlab(\"maximum gamma per document\") +\n  facet_wrap(~k) +\n  geom_vline(aes(xintercept = 1/k),\n             tibble(k=lemma_tm %$% unique(k)),\n             color=\"darkred\")\n```\n\n::: {.cell-output-display}\n![](chapter5_files/figure-pdf/proc_topic-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n## Représentation graphique\n\nÀ partir de la solution retenue aux étapes précédentes, on va représenter les différents topics :\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)     #pour la réplicabilité des résultats\nlda <- LDA(dtm_new, k = 9)\n\nlda_res<-as.data.frame(terms(lda, 25))%>%\n  rename(nom1='Topic 1',nom2='Topic 2', nom3='Topic 3', nom4='Topic 4', nom5='Topic 5',nom6='Topic 6',nom7='Topic 7', nom8='Topic 8', nom9='Topic 9')%>%\n  mutate(rank=as.numeric(row.names(.)))%>%\n  pivot_longer(-rank, names_to = \"topic\", values_to = \"term\")\n\nggplot(lda_res, aes(x=topic, y= rank, group =  term , label = term)) + \n  scale_y_reverse() +\n  geom_text(aes(color=topic,size=8/log(rank)))+\n  theme_minimal()+\n  scale_color_hue()+\n  guides(color=FALSE,size=FALSE)\n```\n\n::: {.cell-output-display}\n![](chapter5_files/figure-pdf/lda_graph-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n# *Theory-Driven LDA*\n\nIci, on va forcer les *topics* grâce à la réalisation d'un dictionnaire. C'est utile quand on cherche à appliquer une théorie qui nous dit ce que l'on cherche à trouver. Par exemple, ici on s'intéresse aux attributs clés des logements oiseaux. Dans d'autre cas, on pourra chercher à expliquer les notes en fonction de *topics* qui reflètent les attributs clés. On peut réaliser le dictionnaire a priori ou après différentes analyses de *topics*, de co-occurences, de fréquence, etc.\n\nOn commence par créer un dictionnaire.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndict<-dictionary(list(produit=c(\"produit*\", \"cage\",\"oiseau\",\"graine*\"),\n                      livraison=c(\"livr*\",\"recepti*\",\"délai\"),\n                      commande=c(\"command*\",\"emballage\",\"envoi*\"),\n                      site=\"*site*\",\n                      prix=c(\"*prix*\",\"frais_port\")\n                      ))\ndict\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDictionary object with 5 key entries.\n- [produit]:\n  - produit*, cage, oiseau, graine*\n- [livraison]:\n  - livr*, recepti*, délai\n- [commande]:\n  - command*, emballage, envoi*\n- [site]:\n  - *site*\n- [prix]:\n  - *prix*, frais_port\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(dfm_lookup(dfm_new,dict))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDocument-feature matrix of: 6 documents, 5 features (73.33% sparse) and 6 docvars.\n    features\ndocs produit livraison commande site prix\n   1       0         0        0    0    0\n   2       0         2        1    0    0\n   3       2         1        0    0    0\n   4       0         0        1    0    0\n   5       0         1        0    0    0\n   6       0         1        0    1    0\n```\n\n\n:::\n:::\n\n\n\nOn utilise ensuite le package 'seededlda' pour lancer le modèle semi-supervisé.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(seededlda)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLe chargement a nécessité le package : proxyC\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttachement du package : 'proxyC'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nL'objet suivant est masqué depuis 'package:stats':\n\n    dist\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttachement du package : 'seededlda'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLes objets suivants sont masqués depuis 'package:topicmodels':\n\n    terms, topics\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nL'objet suivant est masqué depuis 'package:stats':\n\n    terms\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(1234)\nslda<-textmodel_seededlda(dfm_new, dict, residual = T)\nterms(slda,20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      produit                        livraison                     \n [1,] \"oiseau\"                       \"livraison\"                   \n [2,] \"cage\"                         \"livrer\"                      \n [3,] \"graine\"                       \"délai\"                       \n [4,] \"perroquet\"                    \"dire\"                        \n [5,] \"produit_qualité\"              \"bon_produit\"                 \n [6,] \"produit_conforme\"             \"satisfaire\"                  \n [7,] \"avoir\"                        \"problème\"                    \n [8,] \"content\"                      \"satisfait\"                   \n [9,] \"trouver\"                      \"service\"                     \n[10,] \"petit\"                        \"bon\"                         \n[11,] \"jouet\"                        \"top\"                         \n[12,] \"acheter\"                      \"livraison_rapide_produit\"    \n[13,] \"harnais\"                      \"livraison_rapide_recommander\"\n[14,] \"perruche\"                     \"temps\"                       \n[15,] \"produit_bon_qualité\"          \"cher\"                        \n[16,] \"grand\"                        \"impeccable\"                  \n[17,] \"produit_conforme_description\" \"emballer\"                    \n[18,] \"tout\"                         \"livreur\"                     \n[19,] \"passer\"                       \"livraison_temps\"             \n[20,] \"arriver\"                      \"correct\"                     \n      commande              site               prix                      \n [1,] \"commander\"           \"site\"             \"prix\"                    \n [2,] \"recevoir\"            \"rapide\"           \"bon\"                     \n [3,] \"envoi_rapide\"        \"bon_site\"         \"excellent\"               \n [4,] \"emballage\"           \"recommander_site\" \"qualité\"                 \n [5,] \"envoi\"               \"sérieux\"          \"service\"                 \n [6,] \"satisfait\"           \"site_sérieux\"     \"frais_port\"              \n [7,] \"article\"             \"tre\"              \"top\"                     \n [8,] \"conforme\"            \"satisfait\"        \"article\"                 \n [9,] \"commande_recevoir\"   \"siter\"            \"magasin\"                 \n[10,] \"emballer\"            \"redire\"           \"prix_raisonnable\"        \n[11,] \"envoi_rapide_soigné\" \"rapider\"          \"satisfait\"               \n[12,] \"commande_arriver\"    \"premier_commande\" \"professionnel\"           \n[13,] \"commande_passer\"     \"super_site\"       \"super\"                   \n[14,] \"correspondre\"        \"super\"            \"équipe\"                  \n[15,] \"problème\"            \"choix\"            \"réactif\"                 \n[16,] \"content\"             \"autre_site\"       \"téléphone\"               \n[17,] \"commande_livrer\"     \"conseiller\"       \"bon_rapport_qualité_prix\"\n[18,] \"rapidité\"            \"bon_produit\"      \"prix_correct\"            \n[19,] \"rapide\"              \"achat\"            \"trouver\"                 \n[20,] \"envoie\"              \"hésiter\"          \"expédition_rapide\"       \n      other     \n [1,] \"avoir\"   \n [2,] \"faire\"   \n [3,] \"colis\"   \n [4,] \"pouvoir\" \n [5,] \"jour\"    \n [6,] \"fois\"    \n [7,] \"recevoir\"\n [8,] \"attendre\"\n [9,] \"dire\"    \n[10,] \"autre\"   \n[11,] \"aller\"   \n[12,] \"part\"    \n[13,] \"être\"    \n[14,] \"petit\"   \n[15,] \"devoir\"  \n[16,] \"problème\"\n[17,] \"mettre\"  \n[18,] \"attente\" \n[19,] \"voir\"    \n[20,] \"mail\"    \n```\n\n\n:::\n:::\n\n\n\n# Expliquer les notes\n\nDans cette dernière partie, nous allons nous intéresser aux notes et tenter de les expliquer à l'aide de l'analyse de *topics*.\n\n## NPS\n\nDans un premier temps, nous allons regarder le Net Promoter Score (NPS), puis nous étudierons les discours des promoteurs, détracteurs et passifs.\n\nTout d'abord, nous créons nos catégories en fonction des notes.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncol<- c(\"red\",\"gold\", \"chartreuse\")\n\n\ndata<-data %>%\n  mutate(NPS=case_when(note<4~\"Détracteurs\",\n                       note==4~\"Passifs\",\n                       note>4~\"Promoteurs\"))\n\n\nggplot(data, aes(x=note))+\n  geom_histogram(binwidth = 1, aes(fill=NPS))+\n  labs( title= \" Distribution des scores NPS\", \n        subtitle = paste(\"Moyenne du NPS de l'échantillon\",round(mean(data$note),1)), \n        caption = paste(\"Data : TrustPilot, n=\",nrow(data)), \n        y = \"Fréquence\")+ \n  scale_fill_manual(values=col)+\n  theme_light()\n```\n\n::: {.cell-output-display}\n![](chapter5_files/figure-pdf/nps-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nPuis nous réalisons un nuage de mots pour chaque groupe, afin d'avoir une idée de ce qui est exprimé.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndfm_new$NPS<-data$NPS\n# docvars(toks)\n\ndfm_gp <-dfm_new %>%\n    dfm_group(groups = NPS)\n# dfm_gp\n\nstat<- dfm_gp %>% \n  textstat_frequency(n = 30,  groups = NPS)\nstat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       feature frequency rank docfreq       group\n1        avoir       103    1       1 Détracteurs\n2    commander        81    2       1 Détracteurs\n3     recevoir        79    3       1 Détracteurs\n4    livraison        77    4       1 Détracteurs\n5        colis        41    5       1 Détracteurs\n6         site        40    6       1 Détracteurs\n7      pouvoir        38    7       1 Détracteurs\n8      article        38    7       1 Détracteurs\n9       livrer        37    9       1 Détracteurs\n10       faire        34   10       1 Détracteurs\n11        fois        31   11       1 Détracteurs\n12    problème        28   12       1 Détracteurs\n13        dire        28   12       1 Détracteurs\n14    attendre        28   12       1 Détracteurs\n15        jour        28   12       1 Détracteurs\n16      devoir        28   12       1 Détracteurs\n17        cher        26   17       1 Détracteurs\n18      graine        26   17       1 Détracteurs\n19       autre        25   19       1 Détracteurs\n20     envoyer        25   19       1 Détracteurs\n21       payer        25   19       1 Détracteurs\n22     acheter        25   19       1 Détracteurs\n23     trouver        23   23       1 Détracteurs\n24        cage        23   23       1 Détracteurs\n25        long        23   23       1 Détracteurs\n26      oiseau        21   26       1 Détracteurs\n27        déçu        21   26       1 Détracteurs\n28        mois        21   26       1 Détracteurs\n29     réponse        20   29       1 Détracteurs\n30     semaine        20   29       1 Détracteurs\n31       avoir        85    1       1     Passifs\n32   livraison        78    2       1     Passifs\n33   commander        56    3       1     Passifs\n34        site        53    4       1     Passifs\n35    recevoir        50    5       1     Passifs\n36      rapide        42    6       1     Passifs\n37   satisfait        41    7       1     Passifs\n38         bon        40    8       1     Passifs\n39       petit        35    9       1     Passifs\n40     pouvoir        34   10       1     Passifs\n41   perroquet        34   10       1     Passifs\n42       colis        33   12       1     Passifs\n43      oiseau        32   13       1     Passifs\n44     trouver        30   14       1     Passifs\n45       faire        29   15       1     Passifs\n46     article        28   16       1     Passifs\n47  frais_port        28   16       1     Passifs\n48        cher        26   18       1     Passifs\n49    problème        23   19       1     Passifs\n50        dire        23   19       1     Passifs\n51 bon_produit        21   21       1     Passifs\n52      livrer        21   21       1     Passifs\n53    emballer        21   21       1     Passifs\n54       délai        20   24       1     Passifs\n55  satisfaire        20   24       1     Passifs\n56        cage        20   24       1     Passifs\n57     arriver        19   27       1     Passifs\n58        prix        19   27       1     Passifs\n59   emballage        19   27       1     Passifs\n60       super        18   30       1     Passifs\n61      rapide       295    1       1  Promoteurs\n62   satisfait       284    2       1  Promoteurs\n63        site       279    3       1  Promoteurs\n64   livraison       275    4       1  Promoteurs\n65   commander       269    5       1  Promoteurs\n66      oiseau       228    6       1  Promoteurs\n67       avoir       222    7       1  Promoteurs\n68    recevoir       186    8       1  Promoteurs\n69         bon       173    9       1  Promoteurs\n70     sérieux       157   10       1  Promoteurs\n71        dire       150   11       1  Promoteurs\n72     qualité       146   12       1  Promoteurs\n73     service       143   13       1  Promoteurs\n74         top       141   14       1  Promoteurs\n75 bon_produit       138   15       1  Promoteurs\n76   excellent       138   15       1  Promoteurs\n77     article       134   17       1  Promoteurs\n78       super       133   18       1  Promoteurs\n79     content       127   19       1  Promoteurs\n80   perroquet       122   20       1  Promoteurs\n81     trouver       119   21       1  Promoteurs\n82    problème       117   22       1  Promoteurs\n83       faire       111   23       1  Promoteurs\n84    emballer       111   23       1  Promoteurs\n85    conforme       108   25       1  Promoteurs\n86        prix        99   26       1  Promoteurs\n87         tre        93   27       1  Promoteurs\n88       délai        92   28       1  Promoteurs\n89       petit        92   28       1  Promoteurs\n90    rapidité        88   30       1  Promoteurs\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(stat, aes(label = feature)) +\n  geom_text_wordcloud(aes(size=log(frequency), color=group)) +\n  theme_minimal()+\n  facet_wrap(vars(group))+\n  scale_color_manual(values=col)+ \n  labs(title=\"Nuage des 30 mots les plus fréquents (Par groupes)\",\n       caption = \"La taille des mots est proportionnelle au log de leurs fréquences\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in wordcloud_boxes(data_points = points_valid_first, boxes = boxes, :\nSome words could not fit on page. They have been placed at their original\npositions.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](chapter5_files/figure-pdf/keyness1-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nMaintenant, nous nous intéressons à ce qui caractérise chacun des groupes par rapport aux autres, grâce à la mesure du *keyness*.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngraph_promoteur<-textstat_keyness(dfm_gp, target = \"Promoteurs\")%>%\n  textplot_keyness(n = 30L, labelsize = 2,   show_legend = FALSE, \n                     show_reference = FALSE,   color = c(\"Darkgreen\", \"gray\"))+\n  labs(x=NULL)\n\n\ngraph_detracteur <- textstat_keyness(dfm_gp, target = \"Détracteurs\" )%>%\n  textplot_keyness(n = 30L, labelsize = 2,   show_legend = FALSE,   \n                     show_reference = FALSE,   color = c(\"firebrick\", \"gray\"))+ \n  labs(x=NULL)\n\n\ngraph_passif <- textstat_keyness(dfm_gp, target = \"Passifs\")%>%\n  textplot_keyness(n = 30L, labelsize = 2,   show_legend = FALSE,   show_reference = FALSE,    color = c(\"gold2\", \"gray\"))+\n  labs(x=NULL)\n\n\nlibrary(cowplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttachement du package : 'cowplot'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nL'objet suivant est masqué depuis 'package:lubridate':\n\n    stamp\n```\n\n\n:::\n\n```{.r .cell-code}\np<- plot_grid(graph_detracteur, graph_passif ,graph_promoteur,  labels = c('Détracteurs', 'Passifs', 'Promoteurs'), label_size = 10, ncol=3)\n\ntitle <- ggdraw() + draw_label(\"NPS : Les raisons qui conduisent à la recommandation (keyness)\", fontface='bold')\n\nnote <- ggdraw()+ draw_text(\"Les valeurs représentent le keyness des termes.\\nIl mesure leur caractère distinctif par une statistique du chi²\", size=8,x = 0.5, y = 0.5)\n\n\nplot_grid(title, p,note, ncol=1, rel_heights=c(0.1, 1)) # rel_heights values control title margins\n```\n\n::: {.cell-output-display}\n![](chapter5_files/figure-pdf/keyness2-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n## En fonction des topics\n\nMaintenant, nous cherchons à voir la répartition des *topics* dans les notes, pour comprendre si certains *topics* contribuent plus ou moins à la satisfaction.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta<-as.data.frame(slda$theta)%>%mutate(doc_id=as.numeric(row.names(.)))\n\ndata<-inner_join(data, theta)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(doc_id)`\n```\n\n\n:::\n\n```{.r .cell-code}\nfoo<-data%>%select(note, produit, livraison, commande, site,prix, other)%>%\n  pivot_longer(-note, names_to = \"topic\", values_to = \"value\")\n\nggplot(foo,aes(x=note, y=value, group=topic))+\n  geom_bar(position=\"fill\",stat=\"identity\", aes(fill=topic))+\n  scale_fill_brewer(palette=\"Spectral\")+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](chapter5_files/figure-pdf/note-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\n#Pour finir, une petite régression !\nfit<-lm(note~produit+livraison+commande+site+prix, data =data)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = note ~ produit + livraison + commande + site + prix, \n    data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1270 -0.0206  0.1766  0.3033  1.9858 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.51256    0.07178   35.01   <2e-16 ***\nproduit      1.92260    0.11146   17.25   <2e-16 ***\nlivraison    2.45543    0.10907   22.51   <2e-16 ***\ncommande     2.44823    0.10885   22.49   <2e-16 ***\nsite         2.95498    0.10736   27.52   <2e-16 ***\nprix         2.79509    0.10718   26.08   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7591 on 4310 degrees of freedom\nMultiple R-squared:  0.1952,\tAdjusted R-squared:  0.1942 \nF-statistic:   209 on 5 and 4310 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n",
    "supporting": [
      "chapter5_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}