{
  "hash": "9ac6caea2030d38f084daac727b140c5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Annotations et dépendances syntaxiques\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(quanteda)\nlibrary(quanteda.textstats)\nlibrary(quanteda.textplots)\nlibrary(RColorBrewer)\ndisplay.brewer.all()\n```\n:::\n\n\n\n# Les données\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read_csv(\"data/data_trustpilot_oiseaux.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 4388 Columns: 7\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (4): auteur, date, month, comments\ndbl (3): id, year, note\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ndata$nb_caractere<-nchar(data$comments) #on compte le nombre de caractère de chaque commentaire\nsummary(data$nb_caractere)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   12.0    41.0    74.0   104.3   130.0  1571.0 \n```\n\n\n:::\n\n```{.r .cell-code}\nmean(data$nb_caractere)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 104.2974\n```\n\n\n:::\n\n```{.r .cell-code}\nmedian(data$nb_caractere)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 74\n```\n\n\n:::\n\n```{.r .cell-code}\nround(mean(data$nb_caractere),1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 104.3\n```\n\n\n:::\n\n```{.r .cell-code}\nmoy<-round(mean(na.omit(data$nb_caractere)), 1)\n\nggplot(data)+\n  geom_boxplot(aes(nb_caractere))+\n  geom_text(aes(x=500, y=0.2,label=paste(\"Moyenne :\",moy)))+\n  coord_flip()+\n  scale_y_continuous(NULL, breaks = NULL)+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](chapter4_files/figure-pdf/data-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n# Les traitements préliminaires\n\nOn reprend ce qu'on a fait au cours dernier, sans éliminer les termes trop fréquents :\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorpus_oiseaux<-corpus(data, text_field = \"comments\")\n\ntok<-tokens(corpus_oiseaux, remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE)%>%\n  tokens_remove(stopwords(\"fr\"))\n\ndfm<-dfm(tok)\n```\n:::\n\n\n\n# Co-occurrences\n\nOn va maintenant constituer des bi-grammes basés sur de nombreuses co-occurrences entre les termes :\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# textstat_collocations(tok)\n\nhead(textstat_collocations(tok), 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       collocation count count_nested length   lambda        z\n1 livraison rapide   612            0      2 3.587755 56.29325\n2    oiseaux mania   194            0      2 7.111407 38.50542\n3         très bon   291            0      2 3.325458 37.28183\n4        très bien   332            0      2 2.763473 37.07693\n5    bonne qualité   116            0      2 4.440036 33.65412\n```\n\n\n:::\n\n```{.r .cell-code}\ntail(textstat_collocations(tok),10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            collocation count count_nested length    lambda         z\n4046          bien bien     3            0      2 -1.601302 -2.983435\n4047 livraison produits     4            0      2 -1.539254 -3.248433\n4048        site rapide     7            0      2 -1.205217 -3.274181\n4049  commande commande     8            0      2 -1.154362 -3.338450\n4050        bien rapide    10            0      2 -1.111673 -3.567851\n4051    produits rapide     2            0      2 -2.293296 -3.616176\n4052 livraison commande     9            0      2 -1.233460 -3.770310\n4053             très a     2            0      2 -2.581564 -4.071675\n4054      rapide rapide     4            0      2 -2.401230 -5.077424\n4055          très très    22            0      2 -1.110720 -5.196198\n```\n\n\n:::\n\n```{.r .cell-code}\ncolloc<-textstat_collocations(tok, min_count = 10, tolower = TRUE)\nhead(colloc,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        collocation count count_nested length   lambda        z\n1  livraison rapide   612            0      2 3.587755 56.29325\n2     oiseaux mania   194            0      2 7.111407 38.50542\n3          très bon   291            0      2 3.325458 37.28183\n4         très bien   332            0      2 2.763473 37.07693\n5     bonne qualité   116            0      2 4.440036 33.65412\n6         rien dire    93            0      2 5.576935 32.54402\n7       bon produit   146            0      2 3.412030 32.15574\n8      envoi rapide   137            0      2 3.741715 27.61231\n9  produit conforme    94            0      2 3.613662 27.52989\n10  très satisfaite   154            0      2 3.288031 27.11619\n```\n\n\n:::\n\n```{.r .cell-code}\ntail(colloc,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          collocation count count_nested length     lambda         z\n356   livraison merci    10            0      2 -0.4024193 -1.285159\n357 commande produits    11            0      2 -0.3922655 -1.311659\n358       rapide site    13            0      2 -0.4424632 -1.601325\n359  rapide livraison    23            0      2 -0.3478837 -1.653038\n360     bien commande    11            0      2 -0.5705858 -1.910948\n361          rapide a    10            0      2 -0.6915725 -2.214619\n362          a rapide    10            0      2 -0.8863541 -2.840453\n363   commande rapide    21            0      2 -0.6532274 -2.978690\n364       bien rapide    10            0      2 -1.1116732 -3.567851\n365         très très    22            0      2 -1.1107203 -5.196198\n```\n\n\n:::\n\n```{.r .cell-code}\ntok_cooc<-tokens_compound(tok, pattern = colloc[colloc$z>6.97,],join = TRUE)\n\ntok[\"text400\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTokens consisting of 1 document and 7 docvars.\ntext400 :\n[1] \"Excellent\" \"service\"   \"livraison\" \"rapide\"   \n```\n\n\n:::\n\n```{.r .cell-code}\ntok_cooc[\"text400\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTokens consisting of 1 document and 7 docvars.\ntext400 :\n[1] \"Excellent_service\" \"livraison_rapide\" \n```\n\n\n:::\n:::\n\n\n\nAnalyse de fréquence et représentation graphique :\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndfm_cooc<-dfm(tok_cooc)\n\ndfm_cooc2<-dfm_trim(dfm_cooc, max_termfreq = 170)\n\nhead(textstat_frequency(dfm_cooc2),20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           feature frequency rank docfreq group\n1             prix       169    1     160   all\n2          service       165    2     154   all\n3        perroquet       165    2     150   all\n4          oiseaux       165    2     145   all\n5              top       163    5     149   all\n6          qualité       160    6     153   all\n7    oiseaux_mania       142    7     129   all\n8       rapidement       139    8     137   all\n9             tres       127    9     107   all\n10        articles       124   10     115   all\n11        rapidité       124   10     117   all\n12            reçu       122   12     114   all\n13         sérieux       121   13     114   all\n14             car       120   14     111   all\n15           temps       120   14     115   all\n16       satisfait       115   16     108   all\n17        problème       114   17     102   all\n18           comme       114   17     108   all\n19 très_satisfaite       111   19     107   all\n20         graines       107   20      87   all\n```\n\n\n:::\n\n```{.r .cell-code}\ntextplot_wordcloud(dfm_cooc2, max_words = 200, color = brewer.pal(6, \"Set2\"))\n```\n\n::: {.cell-output-display}\n![](chapter4_files/figure-pdf/cooc_viz-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ntok_cooc<-tokens_replace(tok_cooc, c(\"très_rapidement\",\"très_satisfait\"), c(\"très_rapide\",\"très_satisfaite\"))\n\ndfm_cooc<-dfm(tok_cooc)\ntextstat_frequency(dfm_cooc, n=25)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            feature frequency rank docfreq group\n1          commande       715    1     620   all\n2                 a       502    2     412   all\n3         livraison       474    3     432   all\n4              site       401    4     359   all\n5  livraison_rapide       389    5     381   all\n6             merci       380    6     368   all\n7           parfait       361    7     334   all\n8              très       349    8     298   all\n9           produit       331    9     294   all\n10           rapide       328   10     310   all\n11         produits       321   11     292   all\n12       recommande       320   12     313   all\n13             plus       292   13     254   all\n14             bien       280   14     251   all\n15        très_bien       256   15     236   all\n16            super       252   16     232   all\n17             tout       245   17     224   all\n18             j'ai       234   18     189   all\n19            colis       207   19     176   all\n20  très_satisfaite       202   20     195   all\n21            c'est       196   21     168   all\n22         toujours       188   22     163   all\n23      très_rapide       174   23     168   all\n24             prix       169   24     160   all\n25          service       165   25     154   all\n```\n\n\n:::\n\n```{.r .cell-code}\ndfm_cooc2<-dfm_trim(dfm_cooc, max_termfreq = 175)\n\ntextplot_wordcloud(dfm_cooc2, max_words = 100, color = brewer.pal(6, \"Set2\"))\n```\n\n::: {.cell-output-display}\n![](chapter4_files/figure-pdf/cooc_viz-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n## Représentation en réseau des termes co-occurents\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \n# fcm_cooc<-fcm(dfm_cooc2)\n# fcm_cooc\n# topfeatures(fcm_cooc)\n# dim(fcm_cooc)\n# \n# feat<-names(topfeatures(fcm_cooc, 50))\n# fcm_cooc_select<-fcm_select(fcm_cooc, pattern = feat, selection = \"keep\")\n# dim(fcm_cooc_select)\n# \n# textplot_network(fcm_cooc_select, min_freq = 0.8, edge_color = \"red\" , edge_alpha = 0.5, vertex_color = \"blue\",vertex_size = 3, vertex_labelcolor = \"darkblue\", omit_isolated = FALSE)\n# \n# \n# tpfeat<-tibble(feat=names(topfeatures(fcm_cooc,50)),n=topfeatures(fcm_cooc,50))\n# tpfeat<-tpfeat%>%mutate(taille=n/150)\n# \n# textplot_network(fcm_cooc_select, min_freq = 0.8, edge_color = \"red\" , edge_alpha = 0.5, vertex_color = \"blue\",vertex_size = tpfeat$taille, vertex_labelcolor = \"darkblue\", omit_isolated = FALSE)\n# \n# textplot_network(fcm_cooc_select, min_freq = 0.8, edge_color = \"red\" , edge_alpha = 0.5, vertex_color = \"blue\", vertex_labelsize =  tpfeat$taille, vertex_labelcolor = \"darkblue\", omit_isolated = FALSE)\n# \n# \n# \n# textplot_network(fcm_cooc_select, min_freq = 0.8, edge_color = \"red\" , edge_alpha = 0.5, vertex_color = \"blue\",vertex_size = tpfeat$taille, vertex_labelsize =  tpfeat$taille, vertex_labelcolor = \"darkblue\", omit_isolated = FALSE)\n```\n:::\n\n\n\n# Annotations\n\nPour cette partie, on repart du jeu de données brut.\n\n## Détecter les langues\n\nDans le cas d'un corpus composé de plusieurs langues (par exemple, un corpus extrait de twitter), il peut être intéressant de filtrer le corpus à partir de la langue. On utilise un algorithme, qui peut être long à exécuter selon la taille du corpus, et qui est plutôt performant : cld3. Il repose sur un réseau de neurones développé par [Google](https://github.com/ropensci/cld3/blob/master/README.md)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(cld3)\n\ndata$langue<-detect_language(data$comments)\n# data$langue\n\ndata_fr<-data%>%filter(langue==\"fr\")\n```\n:::\n\n\n\n## POS\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(cleanNLP)\n\n# cnlp_init_udpipe(model_name = \"french\")\n# \n# annotate<-cnlp_annotate(data$comments, verbose = 100)\n# ann_token<-annotate$token\n# write_csv2(ann_token, \"annotation_oiseaux.csv\")\n# write_rds(ann_token,\"annotation_oiseaux.rds\")\n\nann_token<-read_rds(\"data/annotation_oiseaux.rds\")\n\nhead(ann_token%>%filter(upos==\"ADJ\"|upos==\"NOUN\"|upos==\"VERB\"),15)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 x 11\n   doc_id   sid tid   token    token_with_ws lemma  upos  xpos  feats tid_source\n    <int> <int> <chr> <chr>    <chr>         <chr>  <chr> <chr> <chr> <chr>     \n 1      1     1 4     super    \"super \"      super  ADJ   <NA>  Gend~ 5         \n 2      1     1 5     service  \"service\"     servi~ NOUN  <NA>  Gend~ 0         \n 3      1     2 2     changez  \"changez \"    chang~ VERB  <NA>  Mood~ 0         \n 4      1     2 5     peut     \"peut \"       pouvo~ VERB  <NA>  Mood~ 2         \n 5      1     2 8     cagnotte \"cagnotte \"   cagnot ADJ   <NA>  Gend~ 9         \n 6      1     2 9     fidélité \"fidélité \"   fidél~ NOUN  <NA>  Gend~ 5         \n 7      1     2 11    est      \"est\"         être   VERB  <NA>  Mood~ 9         \n 8      1     2 15    dirais   \"dirais \"     dir    VERB  <NA>  Mood~ 11        \n 9      1     2 16    inutile  \"inutile \"    inuti~ ADJ   <NA>  Gend~ 15        \n10      2     1 2     délai    \"délai \"      délai  NOUN  <NA>  Gend~ 0         \n11      2     1 5     commande \"commande \"   comma~ NOUN  <NA>  Gend~ 2         \n12      2     1 7     rapide   \"rapide \"     rapide ADJ   <NA>  Gend~ 5         \n13      2     2 2     délais   \"délais \"     délais NOUN  <NA>  Gend~ 14        \n14      2     2 6     commande \"commande \"   comma~ NOUN  <NA>  Gend~ 2         \n15      2     2 8     rapide   \"rapide\"      rapide ADJ   <NA>  Gend~ 6         \n# i 1 more variable: relation <chr>\n```\n\n\n:::\n\n```{.r .cell-code}\nann_token%>%filter(upos==\"ADJ\"|upos==\"NOUN\"|upos==\"VERB\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 34,232 x 11\n   doc_id   sid tid   token    token_with_ws lemma  upos  xpos  feats tid_source\n    <int> <int> <chr> <chr>    <chr>         <chr>  <chr> <chr> <chr> <chr>     \n 1      1     1 4     super    \"super \"      super  ADJ   <NA>  Gend~ 5         \n 2      1     1 5     service  \"service\"     servi~ NOUN  <NA>  Gend~ 0         \n 3      1     2 2     changez  \"changez \"    chang~ VERB  <NA>  Mood~ 0         \n 4      1     2 5     peut     \"peut \"       pouvo~ VERB  <NA>  Mood~ 2         \n 5      1     2 8     cagnotte \"cagnotte \"   cagnot ADJ   <NA>  Gend~ 9         \n 6      1     2 9     fidélité \"fidélité \"   fidél~ NOUN  <NA>  Gend~ 5         \n 7      1     2 11    est      \"est\"         être   VERB  <NA>  Mood~ 9         \n 8      1     2 15    dirais   \"dirais \"     dir    VERB  <NA>  Mood~ 11        \n 9      1     2 16    inutile  \"inutile \"    inuti~ ADJ   <NA>  Gend~ 15        \n10      2     1 2     délai    \"délai \"      délai  NOUN  <NA>  Gend~ 0         \n# i 34,222 more rows\n# i 1 more variable: relation <chr>\n```\n\n\n:::\n\n```{.r .cell-code}\ng<-ann_token%>%group_by(upos)%>%\n  summarise(n=n())%>%\n  filter(!is.na(upos))\n\nggplot(g)+\n  geom_col(aes(reorder(upos,n),n, fill=n), show.legend = FALSE)+\n  scale_fill_fermenter(palette = \"PuRd\", direction = 1)+\n  coord_flip()+\n  labs(title = \"Fréquence des UPOS\", subtitle = \"Corpus Oiseaux Mania\", caption = \"Data TrustPilot\", x=NULL, y=NULL)+\n  theme_dark()\n```\n\n::: {.cell-output-display}\n![](chapter4_files/figure-pdf/ann_POS-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nMaintenant, on va s'intéresser à des catégories grammaticales spécifiques :\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvocab1<-ann_token%>%\n  filter(upos==\"NOUN\")%>%\n  summarise(freq=n(),.by=lemma)%>%\n  filter(freq>55)\n\nggplot(vocab1,aes(x=reorder(lemma,freq),y=freq))+\n  geom_bar(stat=\"identity\",fill=\"lightgreen\")+\n  coord_flip()+\n  theme_minimal()+\n  labs(title = \"Noms communs les plus fréquents\",subtitle = \"Corpus Oiseaux Mania\", caption=\"Data : TrustPilot\",x=\"Noms commun\",y=\"Fréquence\")\n```\n\n::: {.cell-output-display}\n![](chapter4_files/figure-pdf/ann_viz-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\nvocab1bis<-ann_token%>%\n  filter(upos==\"ADJ\")%>%\n  summarise(freq=n(),.by=lemma)%>%\n  filter(freq>55)\n\nggplot(vocab1bis,aes(x=reorder(lemma,freq),y=freq))+\n  geom_bar(stat=\"identity\",fill=\"darkblue\")+\n  coord_flip()+\n  theme_minimal()+\n  labs(title = \"Adjectifs les plus fréquents\",subtitle = \"Corpus Oiseaux Mania\", caption=\"Data : TrustPilot\",x=\"Adjectifs\",y=\"Fréquence\")\n```\n\n::: {.cell-output-display}\n![](chapter4_files/figure-pdf/ann_viz-2.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\nvocab2<-ann_token%>%\n  filter(upos==\"NOUN\" | upos==\"VERB\" | upos==\"ADJ\")%>%\n  summarise(freq=n(),.by=c(lemma,upos))%>%\n  filter(freq>30)%>%\n  mutate(angle= 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(75, 25)))\n\nlibrary(ggwordcloud)\nggplot(vocab2)+\n  geom_text_wordcloud_area(aes(label=lemma, size=freq, color=freq, angle=angle))+\n  scale_size_area(max_size = 24)+\n  scale_color_fermenter(palette = \"Set2\")+\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in wordcloud_boxes(data_points = points_valid_first, boxes = boxes, :\nSome words could not fit on page. They have been placed at their original\npositions.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](chapter4_files/figure-pdf/ann_viz-3.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\nggplot(vocab2)+\n  geom_text_wordcloud_area(aes(label=lemma, size=freq, color=upos, angle=angle))+\n  scale_size_area(max_size = 24)+\n  scale_color_manual(values=c(\"ADJ\"=\"orange\",\"NOUN\"=\"lightgreen\",\"VERB\"=\"purple\"))+\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in wordcloud_boxes(data_points = points_valid_first, boxes = boxes, :\nOne word could not fit on page. It has been placed at its original position.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](chapter4_files/figure-pdf/ann_viz-4.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n# Les dépendances syntaxiques\n\nQuels sont les mots associés aux termes cibles ?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#on met à niveau la racine\nann_racine<- ann_token%>%\n  left_join(ann_token,by= c(\"doc_id\"=\"doc_id\", \"sid\"=\"sid\", \"tid_source\"=\"tid\"), suffix=c(\"\", \"_source\"))\n#on filtre les relation nominales puis celle qui concerne les termes cibles\nfoo<-ann_racine %>%\n  filter(relation == \"amod\"|relation ==\"acl\"|relation ==\"nmod\"|relation ==\"appos\") %>%\n  select(qual = lemma, source = lemma_source)%>%\n  filter(source==\"commande\"|source==\"livraison\"|source==\"produit\"|source==\"prix\")%>% \n  group_by(source,qual)%>%\n  summarise(n=n())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'source'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n```{.r .cell-code}\n# On remet en forme les données\nfoo1<-foo%>%\n  pivot_wider(names_from = source, values_from = n)%>%\n  mutate(across(everything(), ~replace_na(.x,0)))%>%\n  mutate(sum=rowSums(.[,2:5]))%>%\n  filter(sum>15)%>%\n  select(-sum)%>%\n  pivot_longer(!qual, names_to = \"source\", values_to = \"n\")\n\n\n\nggplot(foo1,aes(x=reorder(qual,n), y=n, group=source))+\n  geom_bar(stat=\"identity\",aes(fill=source),position=position_dodge())+\n  coord_flip()+\n  scale_fill_brewer(palette=\"Spectral\",direction = -1)+\n  theme_minimal()+ \n  labs( title=\"Analyse des dépendances nominales\", subtitle = \"les termes du site et du service\",caption = \"Data : TrustPilot sur Oiseaux Mania\", x=\"tokens dépendants\", y=\"Fréquence\", fill=\"Termes\")+\n  facet_wrap(~source, ncol = 4)\n```\n\n::: {.cell-output-display}\n![](chapter4_files/figure-pdf/dep_synt-1.pdf){fig-pos='H'}\n:::\n:::\n",
    "supporting": [
      "chapter4_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}